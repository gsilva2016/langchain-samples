# langchain-merger-service

This service contains the integration with SummaryMergeScore package

## Run the service

You should configure credentials by setting the following environment variables:

* Set HF_ACCESS_TOKEN via `export HF_ACCESS_TOKEN=<YOUR_ACCESS_TOKEN>`

1. Run `python app.py <optional arguments>` to start the FastAPI server. 
This starts the server at `http://localhost:8000/`. The app supports the following arguments:

```python
"--model_id"            desc="Model ID/HuggingFace Model URI"                                   default="llmware/llama-3.2-3b-instruct-ov"
"--device"              desc="The device to run inference on. Currently supports CPU and GPU"   default="GPU"
"--batch_size"          desc="Number of summaries that the Merger processes at once"            default=5
 "--max_new_tokens"     desc="Maximum of tokens generated by the LLM",                          default=512
"--endpoint_uri"        desc="URI to run the FastAPI server on"                                 default="0.0.0.0"
 "--endpoint_port"      desc="Port to run the FastAPI server on"                                default=8000
```

2. The app currently exposes the following endpoint:
* `POST /merge_summaries` - Merges summaries and assigns anomaly scores to the merged summary.

#### Request Body
```json
{
    "summaries": {
        "chunk_0": "text1",
        "chunk_1": "text2",
        ...
    }
}
```

#### Response Body

```json
{
    "overall_summary": "Many strings and summaries",
    "anomaly_score": 0.7
}
```

To see example code of invoking the endpoint with a sample request, please see `tests/test_mergescore_api.py`
